{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mine Twitter - NFL Search Patterns - TEAM\n",
    "\n",
    "\n",
    "Ryan Timbrook (RTIMBROO)  \n",
    "DATE:11/30/2019 <br>\n",
    "Topic: Search Twitter for tweets on specific NFL Players, Coaches, and Teams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objective\n",
    "_____________________________________________________________________________________________\n",
    "Capture popular opinion of peoples tweets on certain NFL characters. \n",
    "Create a corpus of tweets for sentiment analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________\n",
    "### Coding Environment Setup\n",
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages for analysis and modeling\n",
    "import pandas as pd #data frame operations\n",
    "import numpy as np #arrays and math functions\n",
    "import requests\n",
    "import os\n",
    "import io\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "import string\n",
    "from os import path\n",
    "from datetime import date\n",
    "from datetime import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages for twitter\n",
    "import tweepy as tw\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "# Twython packages for twitter\n",
    "from twython import Twython\n",
    "\n",
    "# packages for NLTK\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custome python packages\n",
    "import rtimbroo_utils as br             # custome python helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global properties\n",
    "notebook_file_name = 'search_twitter_nfl_team'\n",
    "report_file_name = 'search_twitter_nfl_team'\n",
    "app_name = 'search_twitter_nfl_team'\n",
    "log_level = 10 # 10-DEBUG, 20-INFO, 30-WARNING, 40-ERROR, 50-CRITICAL\n",
    "\n",
    "# setup working directory structure\n",
    "# set global properties\n",
    "dataDir = './data'\n",
    "outputDir = './output'\n",
    "configDir = './config'\n",
    "logOutDir = './logs'\n",
    "imageDir = './images'\n",
    "modelDir = './models'\n",
    "corpusDir = './corpus'\n",
    "# create base output directories if they don't exist\n",
    "if not os.path.exists(outputDir): os.mkdir(outputDir)\n",
    "if not os.path.exists(logOutDir): os.mkdir(logOutDir)\n",
    "if not os.path.exists(imageDir): os.mkdir(imageDir)\n",
    "if not os.path.exists(modelDir): os.mkdir(modelDir)\n",
    "if not os.path.exists(dataDir): os.mkdir(dataDir)\n",
    "if not os.path.exists(configDir): os.mkdir(configDir)\n",
    "if not os.path.exists(corpusDir): os.mkdir(corpusDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a logger for troubleshooting / data exploration\n",
    "logger = br.getFileLogger(logOutDir+'/',app_name,level=log_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-12-02'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get current date\n",
    "now = datetime.utcnow().isoformat()\n",
    "collection_date = re.findall('^[0-9]{4}-[0-9]{2}-[0-9]{2}',now)\n",
    "collection_date = collection_date[0]\n",
    "collection_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OBTAIN the data   \n",
    "________________________________________________________________________________________________\n",
    "Import external datasets for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter Search API Limits:\n",
    "[Sandbox Package](https://developer.twitter.com/en/pricing/search-fullarchive)\n",
    "\n",
    "* Time frame:\tFull history\n",
    "* Tweets per request:\t100\n",
    "* Counts vs. data:\tData only\n",
    "* Query length:\t128 characters\n",
    "* Operator availability:\tStandard\n",
    "* Rate limit per minute:\t30 requests/min\n",
    "* Enrichments:\tn/a\n",
    "* Dev environments:\t1\t\n",
    "* Monthly Tweet cap:\t5k\t\n",
    "* Rate limit per second: 10 requests/sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Twitter API Object\n",
    "Using Twython 3.6 Twitter API Wrapper\n",
    "[Twython 3.6.0 reference documentation](https://twython.readthedocs.io/en/latest/api.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load twitter credentials\n",
    "with open(f'{configDir}/twitter_credentials.json', 'r') as f:\n",
    "    tw_cred = json.load(f)\n",
    "\n",
    "# setup client header arguments to pass along to the API\n",
    "client_args = {\n",
    "    'headers':{\n",
    "        'User-Agent': 'AI_Public_Sentiment_16860838'\n",
    "    },\n",
    "    'timeout':300,\n",
    "    \n",
    "}\n",
    "    \n",
    "# instantiate object\n",
    "py_tweets = Twython(tw_cred['CONSUMER_KEY'],\n",
    "                    tw_cred['CONSUMER_SECRET'],\n",
    "                    tw_cred['ACCESS_TOKEN'],\n",
    "                    tw_cred['ACCESS_SECRET'],\n",
    "                   client_args=client_args)\n",
    "\n",
    "logger.debug(f'{py_tweets.verify_credentials()}')\n",
    "logger.debug(f'{py_tweets.get_home_timeline()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Search Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set what to search on\n",
    "nfl_type = 'team'\n",
    "search_on = 'houston_texans'\n",
    "\n",
    "# setup base twitter search query\n",
    "search_terms=\"houston texans\"\n",
    "\n",
    "# add filters to search criteria\n",
    "filtered_search_terms = search_terms + \" -filter:retweets\"\n",
    "\n",
    "#search_start_date = '2019-11-23' # limits to the last 7 days\n",
    "\n",
    "# number of tweets to return\n",
    "num_tweets = 100 # sandbox rate limit - 100 tweets per request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search dates (from_date, to_date) - Sunday to Sunday\n",
    "# --- Complete list of the 17 week NFL schedule --- #\n",
    "search_date_ranges = [\n",
    "    #('2019-9-1','2019-9-8'),      # week 1\n",
    "    #('2019-9-8','2019-9-15'),     # week 2\n",
    "    #('2019-9-15','2019-9-22'),    # week 3\n",
    "    #('2019-9-22','2019-9-29'),    # week 4\n",
    "    #('2019-9-29','2019-10-6'),    # week 5\n",
    "    ('2019-10-6','2019-10-13'),   # week 6\n",
    "    ('2019-10-13','2019-10-20'),  # week 7\n",
    "    ('2019-10-20','2019-10-27'),  # week 8\n",
    "    ('2019-10-27','2019-11-3'),   # week 9\n",
    "    ('2019-11-3','2019-11-10'),   # week 10\n",
    "    ('2019-11-10','2019-11-17'),  # week 11\n",
    "    ('2019-11-17','2019-11-24'),  # week 12\n",
    "    ('2019-11-24','2019-12-1'),   # week 13\n",
    "    #('2019-12-1','2019-12-8'),    # week 14\n",
    "    #('2019-12-8','2019-12-15'),   # week 15\n",
    "    #('2019-12-15','2019-12-22'),  # week 16\n",
    "    #('2019-12-22','2019-12-29'),  # week 17\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str_date(str_date):\n",
    "    import time\n",
    "    day_of_week = str_date.split(' ')[0]\n",
    "    month = str_date.split(' ')[1]\n",
    "    day_of_month = str_date.split(' ')[2]\n",
    "    year = str_date.split(' ')[-1]\n",
    "    time_of_day = str_date.split(' ')[3]\n",
    "\n",
    "\n",
    "    new_str_date = f'{month} {day_of_month}, {year}'\n",
    "    ts = time.strptime(new_str_date, '%b %d, %Y')\n",
    "    new_ds_str = f'{ts.tm_year}-{ts.tm_mon}-{ts.tm_mday}'\n",
    "\n",
    "    return new_ds_str, time_of_day, str(ts.tm_year), str(ts.tm_mon), str(ts.tm_mday), str(ts.tm_wday)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert_str_date('Sat Nov 23 21:24:19 +0000 2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function:\n",
    "Returns:\n",
    "'''\n",
    "def config_query(search_term,since=None,until=None,count=100,lang='en',result_type='mixed'):\n",
    "    \n",
    "    # query\n",
    "    search = {\n",
    "        'q':search_term,\n",
    "        'since':since,              # from_date\n",
    "        'until':until,              # Date format YYYY-MM-DD - returns tweets created before the given date\n",
    "        'lang':lang,\n",
    "        'result_type':result_type,    # mixed, recent, popular\n",
    "        'count':count,                # max is 100, defult is 15 per page\n",
    "\n",
    "        #'since_id': ,              # returns results with an ID more recent than the specified ID - if the limit of Tweets has occured since the since_id, the since_id will be forced to the oldest ID available\n",
    "        #'max_id': ,                # returns results with an ID older than or equal to the specified ID\n",
    "    }\n",
    "    \n",
    "    logger.debug(f'config_query: search:\\n{search}')\n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: Cleans tweet text of URLs, HashTags and @Tags\n",
    "Returns: Cleaned text, lists of URLs, HasTags and @Tags\n",
    "'''\n",
    "def clean_tweet_text_meta(text):\n",
    "    \n",
    "    cleaned_text = []\n",
    "    new_text = None\n",
    "    urls = []\n",
    "    hash_tags = []\n",
    "    at_tags = []\n",
    "    \n",
    "    re_hash = re.compile('^#..+')\n",
    "    re_url = re.compile('^http*')\n",
    "    re_at = re.compile('^@.+')\n",
    "    punc_transtable = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "    # loop over tokens collecting meta info and cleaning text\n",
    "    if len(text) > 0:\n",
    "        tokens = text.split(' ')\n",
    "        logger.info(f'tokens: {tokens}')\n",
    "        \n",
    "        for tok in tokens:\n",
    "            \n",
    "            try:\n",
    "                # match Hash Tags\n",
    "                if re.match(re_hash,tok):\n",
    "                    hash_tags.append(tok.translate(punc_transtable))\n",
    "                    # hashtags have meaning in tweet text. remove the # character, keep the rest of the text\n",
    "                    cleaned_text.append(tok[1:])\n",
    "                # match URLs\n",
    "                elif re.match(re_url, tok):\n",
    "                    urls.append(tok)\n",
    "                # match @Tags\n",
    "                elif re.match(re_at,tok):\n",
    "                    at_tags.append(tok)\n",
    "                # keep text in original format for later cleaning techniques\n",
    "                else:\n",
    "                    cleaned_text.append(tok)\n",
    "                \n",
    "            except BaseException as be:\n",
    "                logger.warning(f'clean_tweet_text_meta: ***WARNING*** Caught BaseException: {be}')\n",
    "            \n",
    "    else:\n",
    "        logger.warning(f'clean_tweet_text_meta: ***WARNING***: text is empty: {text}')\n",
    "    \n",
    "    logger.info(f'clean_tweet_text_meta: cleaned tokens: {cleaned_text}')\n",
    "    # join cleaned text back together\n",
    "    new_text = ' '.join(cleaned_text)\n",
    "    \n",
    "    return new_text, urls, hash_tags, at_tags\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test clean_tweet_text_v2\n",
    "#test_tweet = \"Attention, I LOVE WHAT I DO, Thats all Carry On!!! #bullsonparade. #Texans #1 in the Division Houston TEXANS @ HumbÃ¢â‚¬Â¦ https://t.co/qZOYnP424X\"\n",
    "#test_tweet2 = \"@NYYfan2442 @_jliendro @OkcGhost @FieldYates Would be tough to beat KC but we could beat Houston. Not really impresÃ¢â‚¬Â¦ https://t.co/pK2avVllxc\"\n",
    "#tw = clean_tweet_text_meta(test_tweet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function Description: \n",
    "'''\n",
    "def page_search(twitter,query,text_file,raw_file):\n",
    "    results = twitter.cursor(twitter.search,**query, return_pages=True)\n",
    "    # search tweets\n",
    "    tweets_dict = {'id':[],'created_at':[],'date':[],'time':[],'user':[],'text':[],'favorite_count':[], 'year':[], 'month':[], 'day_of_month':[], 'day_of_week':[]}\n",
    "    tweets_text_metadata_dict = {'id':[],'date':[],'user':[],'urls':[],'hash_tags':[],'at_tags':[]}\n",
    "    page_cnt = 0\n",
    "    result_cnt = 0\n",
    "    with io.open(f'{text_file}', 'a',encoding='utf8') as f:\n",
    "        with io.open(f'{raw_file}','a',encoding='utf8') as r:\n",
    "            try: \n",
    "                # page is a list of twitter results\n",
    "                for i, page in enumerate(results):\n",
    "                    page_cnt +=1\n",
    "                    logger.info(f'Page: [{i}]')\n",
    "                    try:\n",
    "                        for j,result in enumerate(page):\n",
    "                            #logger.info(f'result type:{type(result)}')\n",
    "                            #break\n",
    "                            \n",
    "                            result_cnt += 1\n",
    "                            logger.info(f'Result: [{j}]')\n",
    "                            try:\n",
    "                                try:\n",
    "                                    logger.debug(f'{result[\"id_str\"]} | {result[\"user\"][\"screen_name\"]} | {result[\"created_at\"]} | {result[\"text\"]} | {result[\"user\"][\"favourites_count\"]}')\n",
    "                                except BaseException as be:\n",
    "                                    logger.warning(f'page_search: ***WARNING***: Caught BaseException writing debug log file: {be}')\n",
    "                                \n",
    "                                # dump raw tweet to file as json\n",
    "                                #raw_tweet = json.load(result)\n",
    "                                dump = json.dumps(result)\n",
    "                                r.write(dump)\n",
    "                                r.write('\\n')\n",
    "                                \n",
    "                                # dump tweet text to file\n",
    "                                f.write(f'{result[\"id_str\"]} {result[\"text\"]}')\n",
    "                                f.write('\\n')\n",
    "                                \n",
    "                                # add key attributes to tweets dictionary as return results\n",
    "                                tweets_dict['id'].append(result[\"id_str\"])\n",
    "                                tweets_dict['created_at'].append(result[\"created_at\"])\n",
    "                                tweets_dict['favorite_count'].append(result[\"user\"][\"favourites_count\"])\n",
    "                                        \n",
    "                                # call function to parse string date\n",
    "                                date_time = convert_str_date(result[\"created_at\"]) # get datetime components\n",
    "                                \n",
    "                                tweets_dict['date'].append(date_time[0])\n",
    "                                tweets_dict['time'].append(date_time[1])        \n",
    "                                tweets_dict['user'].append(result[\"user\"][\"screen_name\"])\n",
    "                                \n",
    "                                # call function to parse text for metadata\n",
    "                                clean_text = clean_tweet_text_meta(result[\"text\"])\n",
    "                        \n",
    "                                tweets_dict['text'].append(clean_text[0])\n",
    "                                        \n",
    "                                # create dictionary of tweet text metadata\n",
    "                                tweets_text_metadata_dict['id'].append(result[\"id_str\"])\n",
    "                                tweets_text_metadata_dict['date'].append(date_time[0])\n",
    "                                tweets_text_metadata_dict['user'].append(result[\"user\"][\"screen_name\"])\n",
    "                                tweets_text_metadata_dict['urls'].append(clean_text[1])\n",
    "                                tweets_text_metadata_dict['hash_tags'].append(clean_text[2])\n",
    "                                tweets_text_metadata_dict['at_tags'].append(clean_text[3])\n",
    "                                \n",
    "                                # track timeseries attributes for granular reporting and visualizations\n",
    "                                tweets_dict['year'].append(date_time[2])\n",
    "                                tweets_dict['month'].append(date_time[3])\n",
    "                                tweets_dict['day_of_month'].append(date_time[4])\n",
    "                                tweets_dict['day_of_week'].append(date_time[5])\n",
    "                                       \n",
    "                                #break\n",
    "\n",
    "                            except BaseException as be:\n",
    "                                logger.warning(f'**WARNING** Caught BaseException: {be}')\n",
    "                                             \n",
    "                    except BaseException as be:\n",
    "                        logger.warning(f'**WARNING** Caught BaseException: {be}')\n",
    "                    #break\n",
    "            except BaseException as be:\n",
    "                logger.warning(f'**WARNING** Caught BaseException: {be}')\n",
    "    \n",
    "    logger.info(f'page_search: processed page_cnt:[{page_cnt}] | total result_cnt: [{result_cnt}]')\n",
    "    \n",
    "    return pd.DataFrame.from_dict(tweets_dict), pd.DataFrame.from_dict(tweets_text_metadata_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Twitter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Twython 3.6.0 reference documentation](https://twython.readthedocs.io/en/latest/api.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the search iteration for directory creation - this way we won't overwrite potentially useful data already created\n",
    "# set this once, then comment out\n",
    "search_iteration = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "search_range: 2019-10-6_2019-10-13\n",
      "Page: [0]\n",
      "**WARNING** Caught BaseException: generator raised StopIteration\n",
      "page_search: processed page_cnt:[1] | total result_cnt: [0]\n",
      "search_range: 2019-10-13_2019-10-20\n",
      "Page: [0]\n",
      "**WARNING** Caught BaseException: generator raised StopIteration\n",
      "page_search: processed page_cnt:[1] | total result_cnt: [0]\n",
      "search_range: 2019-10-20_2019-10-27\n",
      "Page: [0]\n",
      "**WARNING** Caught BaseException: generator raised StopIteration\n",
      "page_search: processed page_cnt:[1] | total result_cnt: [0]\n",
      "search_range: 2019-10-27_2019-11-3\n",
      "Page: [0]\n",
      "**WARNING** Caught BaseException: generator raised StopIteration\n",
      "page_search: processed page_cnt:[1] | total result_cnt: [0]\n",
      "search_range: 2019-11-3_2019-11-10\n",
      "Page: [0]\n",
      "**WARNING** Caught BaseException: generator raised StopIteration\n",
      "page_search: processed page_cnt:[1] | total result_cnt: [0]\n",
      "search_range: 2019-11-10_2019-11-17\n",
      "Page: [0]\n",
      "**WARNING** Caught BaseException: generator raised StopIteration\n",
      "page_search: processed page_cnt:[1] | total result_cnt: [0]\n",
      "search_range: 2019-11-17_2019-11-24\n",
      "Page: [0]\n",
      "Result: [0]\n",
      "tokens: ['The', '#Texans', 'have', 'signed', 'free', 'agent', 'DE', 'Joel', 'Heath', 'and', 'WR', 'Steven', 'Mitchell', 'Jr.', 'to', 'the', 'active', 'roster.', '\\n\\nHouston', 'placedâ€¦', 'https://t.co/lnCpdgpIjZ']\n",
      "clean_tweet_text_meta: cleaned tokens: ['The', 'Texans', 'have', 'signed', 'free', 'agent', 'DE', 'Joel', 'Heath', 'and', 'WR', 'Steven', 'Mitchell', 'Jr.', 'to', 'the', 'active', 'roster.', '\\n\\nHouston', 'placedâ€¦']\n",
      "Result: [1]\n",
      "tokens: ['Jonathan', 'Williamsâ€™', '13-yard', 'touchdown', 'run', 'in', 'the', 'third', 'quarter', 'of', 'last', 'nightâ€™s', 'game', 'against', 'the', 'Houston', 'Texans', 'was', 'sâ€¦', 'https://t.co/YhxDyyheGC']\n",
      "clean_tweet_text_meta: cleaned tokens: ['Jonathan', 'Williamsâ€™', '13-yard', 'touchdown', 'run', 'in', 'the', 'third', 'quarter', 'of', 'last', 'nightâ€™s', 'game', 'against', 'the', 'Houston', 'Texans', 'was', 'sâ€¦']\n",
      "Page: [1]\n",
      "Result: [0]\n",
      "tokens: ['@TeamCornyn', 'Texans', 'are', 'like', 'Sam', 'Houston,', 'not', 'bought', 'for', 'weasels', 'like', 'you,', 'so', 'donâ€™t', 'babble', 'about', 'the', 'Texas', 'way', 'of', 'life.']\n",
      "clean_tweet_text_meta: cleaned tokens: ['Texans', 'are', 'like', 'Sam', 'Houston,', 'not', 'bought', 'for', 'weasels', 'like', 'you,', 'so', 'donâ€™t', 'babble', 'about', 'the', 'Texas', 'way', 'of', 'life.']\n",
      "Result: [1]\n",
      "tokens: ['Do', 'you', 'need', 'to', 'speak', 'with', '#Houston', '#Texas', 'Criminal', '#Lawyer?', '|', '', 'https://t.co/0ac4DjePfY', '', '#Drug', '#Attorney', '', '|', '#DWI', '', '|â€¦', 'https://t.co/qRzz2X7oCK']\n",
      "clean_tweet_text_meta: cleaned tokens: ['Do', 'you', 'need', 'to', 'speak', 'with', 'Houston', 'Texas', 'Criminal', 'Lawyer?', '|', '', '', 'Drug', 'Attorney', '', '|', 'DWI', '', '|â€¦']\n",
      "Page: [2]\n",
      "Result: [0]\n",
      "tokens: ['Colts', 'lose', 'to', 'Texans:', 'The', 'good,', 'the', 'bad', 'and', 'the', 'ugly', '#GoColts', 'https://t.co/mVOTcUngWm']\n",
      "clean_tweet_text_meta: cleaned tokens: ['Colts', 'lose', 'to', 'Texans:', 'The', 'good,', 'the', 'bad', 'and', 'the', 'ugly', 'GoColts']\n",
      "Result: [1]\n",
      "tokens: ['NFL', 'Houston', 'Texans', 'Stance', 'Socks', 'Size', 'L', '-', 'New', '-', 'https://t.co/TXCnrNejIL', 'https://t.co/v9u13MLqB9']\n",
      "clean_tweet_text_meta: cleaned tokens: ['NFL', 'Houston', 'Texans', 'Stance', 'Socks', 'Size', 'L', '-', 'New', '-']\n",
      "Page: [3]\n",
      "Result: [0]\n",
      "tokens: ['Houston', 'Texans', 'Take', 'Control', 'of', 'the', 'AFC', 'South', 'with', 'win', 'over', 'the', 'Indianapolis', 'Colts.', '@HTOWN4LIFE40', 'recaps', 'the', 'game', 'anâ€¦', 'https://t.co/331qVWpAlY']\n",
      "clean_tweet_text_meta: cleaned tokens: ['Houston', 'Texans', 'Take', 'Control', 'of', 'the', 'AFC', 'South', 'with', 'win', 'over', 'the', 'Indianapolis', 'Colts.', 'recaps', 'the', 'game', 'anâ€¦']\n",
      "Result: [1]\n",
      "tokens: ['Houston', 'Texansâ€™', 'DeAndre', 'Hopkins', 'celebrates', 'with', 'his', 'mum', 'after', 'catching', 'two', 'touchdowns', 'â€“', 'BBC\\xa0Sportâ€¦', 'https://t.co/pVFgxSQxHl']\n",
      "clean_tweet_text_meta: cleaned tokens: ['Houston', 'Texansâ€™', 'DeAndre', 'Hopkins', 'celebrates', 'with', 'his', 'mum', 'after', 'catching', 'two', 'touchdowns', 'â€“', 'BBC\\xa0Sportâ€¦']\n",
      "Page: [4]\n",
      "Result: [0]\n",
      "tokens: ['New', '#Texans', 'from', 'Houston', 'Chronicle', 'â€”', 'McClain:', 'The', 'two', 'ways', 'to', 'look', 'at', 'Texans', 'vs.', 'Patriots', 'https://t.co/YG2GR85TPv']\n",
      "clean_tweet_text_meta: cleaned tokens: ['New', 'Texans', 'from', 'Houston', 'Chronicle', 'â€”', 'McClain:', 'The', 'two', 'ways', 'to', 'look', 'at', 'Texans', 'vs.', 'Patriots']\n",
      "Result: [1]\n",
      "tokens: ['3', 'players', 'the', 'Houston', 'Texans', 'can', 'sign', 'after', 'Dylan', \"Cole's\", 'ACL', 'injury\\nhttps://t.co/kWkJjqh0ON']\n",
      "clean_tweet_text_meta: cleaned tokens: ['3', 'players', 'the', 'Houston', 'Texans', 'can', 'sign', 'after', 'Dylan', \"Cole's\", 'ACL', 'injury\\nhttps://t.co/kWkJjqh0ON']\n",
      "Page: [5]\n",
      "Result: [0]\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 1037, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode characters in position 238-239: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-d2fa7debd29f>\", line 29, in <module>\n",
      "    result_df = page_search(py_tweets,query,tweet_filename,raw_filename)\n",
      "  File \"<ipython-input-13-c6e76114815d>\", line 27, in page_search\n",
      "    logger.debug(f'{result[\"id_str\"]} | {result[\"user\"][\"screen_name\"]} | {result[\"created_at\"]} | {result[\"text\"]} | {result[\"user\"][\"favourites_count\"]}')\n",
      "Message: \"1198000822698889217 | ThatWhiteboy713 | Fri Nov 22 22:10:28 +0000 2019 | @JayDar12 I'm sure your more of a texans hater being from houston. Where I'm at it's all cowboys and that's all you ever hear aboutðŸ¤¢ðŸ¤® | 12212\"\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 1037, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode characters in position 246-247: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-d2fa7debd29f>\", line 29, in <module>\n",
      "    result_df = page_search(py_tweets,query,tweet_filename,raw_filename)\n",
      "  File \"<ipython-input-13-c6e76114815d>\", line 54, in page_search\n",
      "    clean_text = clean_tweet_text_meta(result[\"text\"])\n",
      "  File \"<ipython-input-12-a1f1852b9587>\", line 21, in clean_tweet_text_meta\n",
      "    logger.info(f'tokens: {tokens}')\n",
      "Message: 'tokens: [\\'@JayDar12\\', \"I\\'m\", \\'sure\\', \\'your\\', \\'more\\', \\'of\\', \\'a\\', \\'texans\\', \\'hater\\', \\'being\\', \\'from\\', \\'houston.\\', \\'Where\\', \"I\\'m\", \\'at\\', \"it\\'s\", \\'all\\', \\'cowboys\\', \\'and\\', \"that\\'s\", \\'all\\', \\'you\\', \\'ever\\', \\'hear\\', \\'aboutðŸ¤¢ðŸ¤®\\']'\n",
      "Arguments: ()\n",
      "tokens: ['@JayDar12', \"I'm\", 'sure', 'your', 'more', 'of', 'a', 'texans', 'hater', 'being', 'from', 'houston.', 'Where', \"I'm\", 'at', \"it's\", 'all', 'cowboys', 'and', \"that's\", 'all', 'you', 'ever', 'hear', 'aboutðŸ¤¢ðŸ¤®']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 1037, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode characters in position 264-265: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-d2fa7debd29f>\", line 29, in <module>\n",
      "    result_df = page_search(py_tweets,query,tweet_filename,raw_filename)\n",
      "  File \"<ipython-input-13-c6e76114815d>\", line 54, in page_search\n",
      "    clean_text = clean_tweet_text_meta(result[\"text\"])\n",
      "  File \"<ipython-input-12-a1f1852b9587>\", line 47, in clean_tweet_text_meta\n",
      "    logger.info(f'clean_tweet_text_meta: cleaned tokens: {cleaned_text}')\n",
      "Message: 'clean_tweet_text_meta: cleaned tokens: [\"I\\'m\", \\'sure\\', \\'your\\', \\'more\\', \\'of\\', \\'a\\', \\'texans\\', \\'hater\\', \\'being\\', \\'from\\', \\'houston.\\', \\'Where\\', \"I\\'m\", \\'at\\', \"it\\'s\", \\'all\\', \\'cowboys\\', \\'and\\', \"that\\'s\", \\'all\\', \\'you\\', \\'ever\\', \\'hear\\', \\'aboutðŸ¤¢ðŸ¤®\\']'\n",
      "Arguments: ()\n",
      "clean_tweet_text_meta: cleaned tokens: [\"I'm\", 'sure', 'your', 'more', 'of', 'a', 'texans', 'hater', 'being', 'from', 'houston.', 'Where', \"I'm\", 'at', \"it's\", 'all', 'cowboys', 'and', \"that's\", 'all', 'you', 'ever', 'hear', 'aboutðŸ¤¢ðŸ¤®']\n",
      "Result: [1]\n",
      "tokens: ['Houston', 'Texans', 'Podcast:', 'Week', 'Twelve', 'NFL', 'Preview', 'https://t.co/jBBs951Zuk', 'https://t.co/GrLt2JBFrh']\n",
      "clean_tweet_text_meta: cleaned tokens: ['Houston', 'Texans', 'Podcast:', 'Week', 'Twelve', 'NFL', 'Preview']\n",
      "Page: [6]\n",
      "Result: [0]\n",
      "tokens: ['Imagine', 'Texans', 'really', 'believing', 'their', 'second', 'rate', 'Whataburger', 'is', 'on', 'the', 'same', 'level', 'as', '#InNOut.', 'Congrats', 'Houston,', \"y'â€¦\", 'https://t.co/jBMzgjmJJM']\n",
      "clean_tweet_text_meta: cleaned tokens: ['Imagine', 'Texans', 'really', 'believing', 'their', 'second', 'rate', 'Whataburger', 'is', 'on', 'the', 'same', 'level', 'as', 'InNOut.', 'Congrats', 'Houston,', \"y'â€¦\"]\n",
      "Result: [1]\n",
      "tokens: [\"Colts'\", 'control', 'of', 'division', 'goes', 'south', 'with', 'loss', 'to', 'Texans', 'https://t.co/D60izzZSlU', 'https://t.co/2Uobrt04FQ']\n",
      "clean_tweet_text_meta: cleaned tokens: [\"Colts'\", 'control', 'of', 'division', 'goes', 'south', 'with', 'loss', 'to', 'Texans']\n",
      "Page: [7]\n",
      "Result: [0]\n",
      "tokens: ['Houston', 'Texansâ€™', 'DeAndre', 'Hopkins', 'celebrates', 'with', 'his', 'mum', 'after', 'catching', 'two\\xa0touchdowns', 'https://t.co/hMTpAcTvpj', 'https://t.co/RuSBNRGz0R']\n",
      "clean_tweet_text_meta: cleaned tokens: ['Houston', 'Texansâ€™', 'DeAndre', 'Hopkins', 'celebrates', 'with', 'his', 'mum', 'after', 'catching', 'two\\xa0touchdowns']\n",
      "Result: [1]\n",
      "tokens: ['Houston', 'Texansâ€™', 'DeAndre', 'Hopkins', 'celebrates', 'with', 'his', 'mum', 'after', 'catching', 'two\\xa0touchdowns', 'https://t.co/CJbNedpyWb', 'https://t.co/KLqhEFhWJa']\n",
      "clean_tweet_text_meta: cleaned tokens: ['Houston', 'Texansâ€™', 'DeAndre', 'Hopkins', 'celebrates', 'with', 'his', 'mum', 'after', 'catching', 'two\\xa0touchdowns']\n",
      "Page: [8]\n",
      "Result: [0]\n",
      "tokens: ['Per', '@AdamSchefter', 'the', '#Bills', 'hosted', 'OT', 'Seantrel', 'Henderson', 'who', 'played', 'for', 'Buffalo', 'from', '2014-2017.', 'He', 'recently', 'has', 'plâ€¦', 'https://t.co/QXedTArXKr']\n",
      "clean_tweet_text_meta: cleaned tokens: ['Per', 'the', 'Bills', 'hosted', 'OT', 'Seantrel', 'Henderson', 'who', 'played', 'for', 'Buffalo', 'from', '2014-2017.', 'He', 'recently', 'has', 'plâ€¦']\n",
      "Result: [1]\n",
      "tokens: ['After', 'feeding', 'my', 'family', 'In-N-Out', 'tonight.', '#houston', '#Frozen2', '#FridayFeeling', '#Texans', '#InNOut', 'https://t.co/lg9PezTqn5']\n",
      "clean_tweet_text_meta: cleaned tokens: ['After', 'feeding', 'my', 'family', 'In-N-Out', 'tonight.', 'houston', 'Frozen2', 'FridayFeeling', 'Texans', 'InNOut']\n",
      "Page: [9]\n",
      "**WARNING** Caught BaseException: generator raised StopIteration\n",
      "page_search: processed page_cnt:[10] | total result_cnt: [18]\n",
      "search_range: 2019-11-24_2019-12-1\n",
      "Page: [0]\n",
      "Result: [0]\n",
      "tokens: ['The', '#Texans', 'have', 'signed', 'NT', 'Eddie', 'Vanderdoes', 'to', 'the', 'active', 'roster', 'from', 'the', 'practice', 'squad.', 'He', 'is', 'No.', '95.', '\\n\\nHouston', 'pâ€¦', 'https://t.co/xRSg8eowhV']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clean_tweet_text_meta: cleaned tokens: ['The', 'Texans', 'have', 'signed', 'NT', 'Eddie', 'Vanderdoes', 'to', 'the', 'active', 'roster', 'from', 'the', 'practice', 'squad.', 'He', 'is', 'No.', '95.', '\\n\\nHouston', 'pâ€¦']\n",
      "Result: [1]\n",
      "tokens: ['\"Itâ€™s', 'an', 'excellent', 'football', 'team', 'and', 'thatâ€™s', 'why', 'theyâ€™re', '10-1,', 'and', 'itâ€™s', 'a', 'big', 'challenge', 'for', 'us.\"\\n\\nWhat', 'the', 'Texans', 'arâ€¦', 'https://t.co/9N1QubCyhi']\n",
      "clean_tweet_text_meta: cleaned tokens: ['\"Itâ€™s', 'an', 'excellent', 'football', 'team', 'and', 'thatâ€™s', 'why', 'theyâ€™re', '10-1,', 'and', 'itâ€™s', 'a', 'big', 'challenge', 'for', 'us.\"\\n\\nWhat', 'the', 'Texans', 'arâ€¦']\n",
      "Page: [1]\n",
      "Result: [0]\n",
      "tokens: ['Iâ€™ve', 'spent', 'years', 'working', 'in', 'the', '#Houston', 'community,', 'so', 'Iâ€™m', 'aware', 'how', 'low', 'income', 'families', 'suffer.', 'I', 'will', 'strengthenâ€¦', 'https://t.co/noypWlSqWm']\n",
      "clean_tweet_text_meta: cleaned tokens: ['Iâ€™ve', 'spent', 'years', 'working', 'in', 'the', 'Houston', 'community,', 'so', 'Iâ€™m', 'aware', 'how', 'low', 'income', 'families', 'suffer.', 'I', 'will', 'strengthenâ€¦']\n",
      "Result: [1]\n",
      "tokens: ['New', '#Texans', 'from', 'Houston', 'Chronicle', 'â€”', \"Texans'\", 'Deshaun', 'Watson', 'has', 'learned', 'from', 'Tom', \"Brady's\", 'example', 'https://t.co/am9pgEODlH']\n",
      "clean_tweet_text_meta: cleaned tokens: ['New', 'Texans', 'from', 'Houston', 'Chronicle', 'â€”', \"Texans'\", 'Deshaun', 'Watson', 'has', 'learned', 'from', 'Tom', \"Brady's\", 'example']\n",
      "Page: [2]\n",
      "Result: [0]\n",
      "tokens: ['New', '#Texans', 'from', 'Houston', 'Chronicle', 'â€”', 'Texans', 'vs.', 'Patriots:', 'John', \"McClain's\", 'scouting', 'report', 'https://t.co/vQn6VfS73X']\n",
      "clean_tweet_text_meta: cleaned tokens: ['New', 'Texans', 'from', 'Houston', 'Chronicle', 'â€”', 'Texans', 'vs.', 'Patriots:', 'John', \"McClain's\", 'scouting', 'report']\n",
      "Result: [1]\n",
      "tokens: ['Houston', 'Texans', 'Antigua', \"Men's\", 'Polo', 'Shirt', 'Size', '3XL', '-', 'https://t.co/a1YtE0hHfF', 'https://t.co/YiASaPbGqB']\n",
      "clean_tweet_text_meta: cleaned tokens: ['Houston', 'Texans', 'Antigua', \"Men's\", 'Polo', 'Shirt', 'Size', '3XL', '-']\n",
      "Page: [3]\n",
      "Result: [0]\n",
      "tokens: ['New', '#Texans', 'from', 'Houston', 'Chronicle', 'â€”', 'Texans', 'vs.', 'Patriots:', 'John', \"McClain's\", 'scouting', 'report', 'https://t.co/JpgBsaJoeP']\n",
      "clean_tweet_text_meta: cleaned tokens: ['New', 'Texans', 'from', 'Houston', 'Chronicle', 'â€”', 'Texans', 'vs.', 'Patriots:', 'John', \"McClain's\", 'scouting', 'report']\n",
      "Result: [1]\n",
      "tokens: ['New', '#Texans', 'from', 'Houston', 'Chronicle', 'â€”', 'Texans', 'vs.', 'Patriots:', 'John', \"McClain's\", 'keys', 'to', 'victory', 'https://t.co/1hEcYaAyVU']\n",
      "clean_tweet_text_meta: cleaned tokens: ['New', 'Texans', 'from', 'Houston', 'Chronicle', 'â€”', 'Texans', 'vs.', 'Patriots:', 'John', \"McClain's\", 'keys', 'to', 'victory']\n",
      "Page: [4]\n",
      "Result: [0]\n",
      "tokens: ['WATCH', 'LIVE:', 'New', 'England', 'Patriots', 'quarterback', 'Tom', 'Brady', 'speaking', 'ahead', 'of', \"Sunday's\", 'game', 'against', 'the', 'Houston', 'Texans.â€¦', 'https://t.co/0jW7E2YBsG']\n",
      "clean_tweet_text_meta: cleaned tokens: ['WATCH', 'LIVE:', 'New', 'England', 'Patriots', 'quarterback', 'Tom', 'Brady', 'speaking', 'ahead', 'of', \"Sunday's\", 'game', 'against', 'the', 'Houston', 'Texans.â€¦']\n",
      "Result: [1]\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 1037, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\U0001f4ec' in position 102: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-d2fa7debd29f>\", line 29, in <module>\n",
      "    result_df = page_search(py_tweets,query,tweet_filename,raw_filename)\n",
      "  File \"<ipython-input-13-c6e76114815d>\", line 27, in page_search\n",
      "    logger.debug(f'{result[\"id_str\"]} | {result[\"user\"][\"screen_name\"]} | {result[\"created_at\"]} | {result[\"text\"]} | {result[\"user\"][\"favourites_count\"]}')\n",
      "Message: \"1200488426035912710 | NBCSBoston | Fri Nov 29 18:55:19 +0000 2019 | ðŸ“¬ You've got #Patriots questions,  @PhilAPerry has answers in the weekly #FridayBag.\\n\\nðŸˆ Can the Pats offense pop thâ€¦ https://t.co/ubZXVpXUAz | 4317\"\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 1037, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\U0001f4ec' in position 43: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-d2fa7debd29f>\", line 29, in <module>\n",
      "    result_df = page_search(py_tweets,query,tweet_filename,raw_filename)\n",
      "  File \"<ipython-input-13-c6e76114815d>\", line 54, in page_search\n",
      "    clean_text = clean_tweet_text_meta(result[\"text\"])\n",
      "  File \"<ipython-input-12-a1f1852b9587>\", line 21, in clean_tweet_text_meta\n",
      "    logger.info(f'tokens: {tokens}')\n",
      "Message: 'tokens: [\\'ðŸ“¬\\', \"You\\'ve\", \\'got\\', \\'#Patriots\\', \\'questions,\\', \\'\\', \\'@PhilAPerry\\', \\'has\\', \\'answers\\', \\'in\\', \\'the\\', \\'weekly\\', \\'#FridayBag.\\\\n\\\\nðŸˆ\\', \\'Can\\', \\'the\\', \\'Pats\\', \\'offense\\', \\'pop\\', \\'thâ€¦\\', \\'https://t.co/ubZXVpXUAz\\']'\n",
      "Arguments: ()\n",
      "tokens: ['ðŸ“¬', \"You've\", 'got', '#Patriots', 'questions,', '', '@PhilAPerry', 'has', 'answers', 'in', 'the', 'weekly', '#FridayBag.\\n\\nðŸˆ', 'Can', 'the', 'Pats', 'offense', 'pop', 'thâ€¦', 'https://t.co/ubZXVpXUAz']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 1037, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\U0001f4ec' in position 74: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-d2fa7debd29f>\", line 29, in <module>\n",
      "    result_df = page_search(py_tweets,query,tweet_filename,raw_filename)\n",
      "  File \"<ipython-input-13-c6e76114815d>\", line 54, in page_search\n",
      "    clean_text = clean_tweet_text_meta(result[\"text\"])\n",
      "  File \"<ipython-input-12-a1f1852b9587>\", line 47, in clean_tweet_text_meta\n",
      "    logger.info(f'clean_tweet_text_meta: cleaned tokens: {cleaned_text}')\n",
      "Message: 'clean_tweet_text_meta: cleaned tokens: [\\'ðŸ“¬\\', \"You\\'ve\", \\'got\\', \\'Patriots\\', \\'questions,\\', \\'\\', \\'has\\', \\'answers\\', \\'in\\', \\'the\\', \\'weekly\\', \\'FridayBag.\\\\n\\\\nðŸˆ\\', \\'Can\\', \\'the\\', \\'Pats\\', \\'offense\\', \\'pop\\', \\'thâ€¦\\']'\n",
      "Arguments: ()\n",
      "clean_tweet_text_meta: cleaned tokens: ['ðŸ“¬', \"You've\", 'got', 'Patriots', 'questions,', '', 'has', 'answers', 'in', 'the', 'weekly', 'FridayBag.\\n\\nðŸˆ', 'Can', 'the', 'Pats', 'offense', 'pop', 'thâ€¦']\n",
      "Page: [5]\n",
      "Result: [0]\n",
      "tokens: ['@NYYfan2442', '@_jliendro', '@OkcGhost', '@FieldYates', 'Would', 'be', 'tough', 'to', 'beat', 'KC', 'but', 'we', 'could', 'beat', 'Houston.', 'Not', 'really', 'impresâ€¦', 'https://t.co/pK2avVllxc']\n",
      "clean_tweet_text_meta: cleaned tokens: ['Would', 'be', 'tough', 'to', 'beat', 'KC', 'but', 'we', 'could', 'beat', 'Houston.', 'Not', 'really', 'impresâ€¦']\n",
      "Page: [6]\n",
      "**WARNING** Caught BaseException: generator raised StopIteration\n",
      "page_search: processed page_cnt:[7] | total result_cnt: [11]\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 1037, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\U0001f4ec' in position 1801: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-d2fa7debd29f>\", line 31, in <module>\n",
      "    logger.debug(f'search result df: \\n{result_df}')\n",
      "Message: 'search result df: \\n(                     id                      created_at        date      time  \\\\\\n0   1200893170017603585  Sat Nov 30 21:43:37 +0000 2019  2019-11-30  21:43:37   \\n1   1200504705283084288  Fri Nov 29 20:00:00 +0000 2019  2019-11-29  20:00:00   \\n2   1200503267178024960  Fri Nov 29 19:54:17 +0000 2019  2019-11-29  19:54:17   \\n3   1200502032995622915  Fri Nov 29 19:49:23 +0000 2019  2019-11-29  19:49:23   \\n4   1200501335705235457  Fri Nov 29 19:46:37 +0000 2019  2019-11-29  19:46:37   \\n5   1200501288259248128  Fri Nov 29 19:46:26 +0000 2019  2019-11-29  19:46:26   \\n6   1200500727170445312  Fri Nov 29 19:44:12 +0000 2019  2019-11-29  19:44:12   \\n7   1200490973828173824  Fri Nov 29 19:05:26 +0000 2019  2019-11-29  19:05:26   \\n8   1200490229565661187  Fri Nov 29 19:02:29 +0000 2019  2019-11-29  19:02:29   \\n9   1200488426035912710  Fri Nov 29 18:55:19 +0000 2019  2019-11-29  18:55:19   \\n10  1200487820453765120  Fri Nov 29 18:52:55 +0000 2019  2019-11-29  18:52:55   \\n\\n              user                                               text  \\\\\\n0         TexansPR  The Texans have signed NT Eddie Vanderdoes to ...   \\n1         Patriots  \"Itâ€™s an excellent football team and thatâ€™s wh...   \\n2      plummer4hou  Iâ€™ve spent years working in the Houston commun...   \\n3        GregRajan  New Texans from Houston Chronicle â€” Texans\\' De...   \\n4   McClain_on_NFL  New Texans from Houston Chronicle â€” Texans vs....   \\n5      TexansStuff  Houston Texans Antigua Men\\'s Polo Shirt Size 3...   \\n6        GregRajan  New Texans from Houston Chronicle â€” Texans vs....   \\n7   McClain_on_NFL  New Texans from Houston Chronicle â€” Texans vs....   \\n8            7News  WATCH LIVE: New England Patriots quarterback T...   \\n9       NBCSBoston  ðŸ“¬ You\\'ve got Patriots questions,  has answers ...   \\n10   denis27543437  Would be tough to beat KC but we could beat Ho...   \\n\\n    favorite_count  year month day_of_month day_of_week  \\n0               63  2019    11           30           5  \\n1            14693  2019    11           29           4  \\n2              775  2019    11           29           4  \\n3              401  2019    11           29           4  \\n4              451  2019    11           29           4  \\n5                6  2019    11           29           4  \\n6              401  2019    11           29           4  \\n7              451  2019    11           29           4  \\n8             4038  2019    11           29           4  \\n9             4317  2019    11           29           4  \\n10             235  2019    11           29           4  ,                      id        date            user  \\\\\\n0   1200893170017603585  2019-11-30        TexansPR   \\n1   1200504705283084288  2019-11-29        Patriots   \\n2   1200503267178024960  2019-11-29     plummer4hou   \\n3   1200502032995622915  2019-11-29       GregRajan   \\n4   1200501335705235457  2019-11-29  McClain_on_NFL   \\n5   1200501288259248128  2019-11-29     TexansStuff   \\n6   1200500727170445312  2019-11-29       GregRajan   \\n7   1200490973828173824  2019-11-29  McClain_on_NFL   \\n8   1200490229565661187  2019-11-29           7News   \\n9   1200488426035912710  2019-11-29      NBCSBoston   \\n10  1200487820453765120  2019-11-29   denis27543437   \\n\\n                                                 urls  \\\\\\n0                           [https://t.co/xRSg8eowhV]   \\n1                           [https://t.co/9N1QubCyhi]   \\n2                           [https://t.co/noypWlSqWm]   \\n3                           [https://t.co/am9pgEODlH]   \\n4                           [https://t.co/vQn6VfS73X]   \\n5   [https://t.co/a1YtE0hHfF, https://t.co/YiASaPb...   \\n6                           [https://t.co/JpgBsaJoeP]   \\n7                           [https://t.co/1hEcYaAyVU]   \\n8                           [https://t.co/0jW7E2YBsG]   \\n9                           [https://t.co/ubZXVpXUAz]   \\n10                          [https://t.co/pK2avVllxc]   \\n\\n                     hash_tags  \\\\\\n0                     [Texans]   \\n1                           []   \\n2                    [Houston]   \\n3                     [Texans]   \\n4                     [Texans]   \\n5                           []   \\n6                     [Texans]   \\n7                     [Texans]   \\n8                           []   \\n9   [Patriots, FridayBag\\\\n\\\\nðŸˆ]   \\n10                          []   \\n\\n                                              at_tags  \\n0                                                  []  \\n1                                                  []  \\n2                                                  []  \\n3                                                  []  \\n4                                                  []  \\n5                                                  []  \\n6                                                  []  \\n7                                                  []  \\n8                                                  []  \\n9                                       [@PhilAPerry]  \\n10  [@NYYfan2442, @_jliendro, @OkcGhost, @FieldYates]  )'\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Execute Twitter search by pre-configured date ranges\n",
    "'''\n",
    "search_iteration +=1 # each time this block of code is ran, the search iteration will update and create a new output directory structure\n",
    "search_range_results_df = pd.DataFrame()\n",
    "search_tweets_text_meta_df = pd.DataFrame()\n",
    "\n",
    "# execute search by date ranges\n",
    "for dates in search_date_ranges:\n",
    "    search_range = f'{dates[0]}_{dates[1]}'\n",
    "    logger.info(f'search_range: {search_range}')\n",
    "    \n",
    "    # output file names based on date range search\n",
    "    outputPath = f'{dataDir}/{nfl_type}/{search_on}/v{search_iteration}/{search_range}'\n",
    "    if not os.path.exists(outputPath): os.makedirs(outputPath)\n",
    "        \n",
    "    tweet_filename=f'{outputPath}/tweet_text.txt'\n",
    "    raw_filename=f'{outputPath}/tweet_raw.txt'\n",
    "        \n",
    "    if not os.path.exists(f'{tweet_filename}'): open(f'{tweet_filename}', 'a').close()\n",
    "    if not os.path.exists(f'{raw_filename}'): open(f'{raw_filename}', 'a').close()\n",
    "    \n",
    "    \n",
    "    # configure query by dates\n",
    "    query = config_query(filtered_search_terms,since=dates[0],until=dates[1],count=2)\n",
    "    #break\n",
    "    \n",
    "    #------- EXECUTES TWITTER SEARCH -------------------#\n",
    "    result_df = page_search(py_tweets,query,tweet_filename,raw_filename) \n",
    "    \n",
    "    logger.debug(f'search result df: \\n{result_df}')\n",
    "    \n",
    "    # merge dataframes - complete table of search results collected and written out to csv file in code block below\n",
    "    search_range_results_df = search_range_results_df.append(result_df[0], ignore_index=True)\n",
    "    search_tweets_text_meta_df = search_tweets_text_meta_df.append(result_df[1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1198351595840389121</td>\n",
       "      <td>Sat Nov 23 21:24:19 +0000 2019</td>\n",
       "      <td>2019-11-23</td>\n",
       "      <td>21:24:19</td>\n",
       "      <td>TexansPR</td>\n",
       "      <td>The Texans have signed free agent DE Joel Heat...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1198011151688372224</td>\n",
       "      <td>Fri Nov 22 22:51:31 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>22:51:31</td>\n",
       "      <td>AWalkerColts</td>\n",
       "      <td>Jonathan Williamsâ€™ 13-yard touchdown run in th...</td>\n",
       "      <td>9155.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1198009485375225858</td>\n",
       "      <td>Fri Nov 22 22:44:53 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>22:44:53</td>\n",
       "      <td>waemory</td>\n",
       "      <td>Texans are like Sam Houston, not bought for we...</td>\n",
       "      <td>925.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1198008143642365952</td>\n",
       "      <td>Fri Nov 22 22:39:34 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>22:39:34</td>\n",
       "      <td>Felonies4Less</td>\n",
       "      <td>Do you need to speak with Houston Texas Crimin...</td>\n",
       "      <td>8227.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1198008131822981120</td>\n",
       "      <td>Fri Nov 22 22:39:31 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>22:39:31</td>\n",
       "      <td>Colts_TT</td>\n",
       "      <td>Colts lose to Texans: The good, the bad and th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                      created_at        date      time  \\\n",
       "0  1198351595840389121  Sat Nov 23 21:24:19 +0000 2019  2019-11-23  21:24:19   \n",
       "1  1198011151688372224  Fri Nov 22 22:51:31 +0000 2019  2019-11-22  22:51:31   \n",
       "2  1198009485375225858  Fri Nov 22 22:44:53 +0000 2019  2019-11-22  22:44:53   \n",
       "3  1198008143642365952  Fri Nov 22 22:39:34 +0000 2019  2019-11-22  22:39:34   \n",
       "4  1198008131822981120  Fri Nov 22 22:39:31 +0000 2019  2019-11-22  22:39:31   \n",
       "\n",
       "            user                                               text  \\\n",
       "0       TexansPR  The Texans have signed free agent DE Joel Heat...   \n",
       "1   AWalkerColts  Jonathan Williamsâ€™ 13-yard touchdown run in th...   \n",
       "2        waemory  Texans are like Sam Houston, not bought for we...   \n",
       "3  Felonies4Less  Do you need to speak with Houston Texas Crimin...   \n",
       "4       Colts_TT  Colts lose to Texans: The good, the bad and th...   \n",
       "\n",
       "   favorite_count  year month day_of_month day_of_week  \n",
       "0            63.0  2019    11           23           5  \n",
       "1          9155.0  2019    11           22           4  \n",
       "2           925.0  2019    11           22           4  \n",
       "3          8227.0  2019    11           22           4  \n",
       "4             0.0  2019    11           22           4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_range_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>urls</th>\n",
       "      <th>hash_tags</th>\n",
       "      <th>at_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1198351595840389121</td>\n",
       "      <td>2019-11-23</td>\n",
       "      <td>TexansPR</td>\n",
       "      <td>[https://t.co/lnCpdgpIjZ]</td>\n",
       "      <td>[Texans]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1198011151688372224</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>AWalkerColts</td>\n",
       "      <td>[https://t.co/YhxDyyheGC]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1198009485375225858</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>waemory</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@TeamCornyn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1198008143642365952</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>Felonies4Less</td>\n",
       "      <td>[https://t.co/0ac4DjePfY, https://t.co/qRzz2X7...</td>\n",
       "      <td>[Houston, Texas, Lawyer, Drug, Attorney, DWI]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1198008131822981120</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>Colts_TT</td>\n",
       "      <td>[https://t.co/mVOTcUngWm]</td>\n",
       "      <td>[GoColts]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id        date           user  \\\n",
       "0  1198351595840389121  2019-11-23       TexansPR   \n",
       "1  1198011151688372224  2019-11-22   AWalkerColts   \n",
       "2  1198009485375225858  2019-11-22        waemory   \n",
       "3  1198008143642365952  2019-11-22  Felonies4Less   \n",
       "4  1198008131822981120  2019-11-22       Colts_TT   \n",
       "\n",
       "                                                urls  \\\n",
       "0                          [https://t.co/lnCpdgpIjZ]   \n",
       "1                          [https://t.co/YhxDyyheGC]   \n",
       "2                                                 []   \n",
       "3  [https://t.co/0ac4DjePfY, https://t.co/qRzz2X7...   \n",
       "4                          [https://t.co/mVOTcUngWm]   \n",
       "\n",
       "                                       hash_tags        at_tags  \n",
       "0                                       [Texans]             []  \n",
       "1                                             []             []  \n",
       "2                                             []  [@TeamCornyn]  \n",
       "3  [Houston, Texas, Lawyer, Drug, Attorney, DWI]             []  \n",
       "4                                      [GoColts]             []  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tweets_text_meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1198011151688372224</td>\n",
       "      <td>Fri Nov 22 22:51:31 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>22:51:31</td>\n",
       "      <td>AWalkerColts</td>\n",
       "      <td>Jonathan Williamsâ€™ 13-yard touchdown run in th...</td>\n",
       "      <td>9155.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1198009485375225858</td>\n",
       "      <td>Fri Nov 22 22:44:53 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>22:44:53</td>\n",
       "      <td>waemory</td>\n",
       "      <td>Texans are like Sam Houston, not bought for we...</td>\n",
       "      <td>925.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1198008143642365952</td>\n",
       "      <td>Fri Nov 22 22:39:34 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>22:39:34</td>\n",
       "      <td>Felonies4Less</td>\n",
       "      <td>Do you need to speak with Houston Texas Crimin...</td>\n",
       "      <td>8227.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1198008131822981120</td>\n",
       "      <td>Fri Nov 22 22:39:31 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>22:39:31</td>\n",
       "      <td>Colts_TT</td>\n",
       "      <td>Colts lose to Texans: The good, the bad and th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1198006766241505280</td>\n",
       "      <td>Fri Nov 22 22:34:05 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>22:34:05</td>\n",
       "      <td>TexansStuff</td>\n",
       "      <td>NFL Houston Texans Stance Socks Size L - New -</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1198005780819169281</td>\n",
       "      <td>Fri Nov 22 22:30:10 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>22:30:10</td>\n",
       "      <td>OTHeroics1</td>\n",
       "      <td>Houston Texans Take Control of the AFC South w...</td>\n",
       "      <td>10702.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1198003339352530945</td>\n",
       "      <td>Fri Nov 22 22:20:28 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>22:20:28</td>\n",
       "      <td>avpnews_live</td>\n",
       "      <td>Houston Texansâ€™ DeAndre Hopkins celebrates wit...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1198001802584764421</td>\n",
       "      <td>Fri Nov 22 22:14:22 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>22:14:22</td>\n",
       "      <td>ChronicleTexans</td>\n",
       "      <td>New Texans from Houston Chronicle â€” McClain: T...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1198000912985407488</td>\n",
       "      <td>Fri Nov 22 22:10:50 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>22:10:50</td>\n",
       "      <td>Texans_TT</td>\n",
       "      <td>3 players the Houston Texans can sign after Dy...</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1198000822698889217</td>\n",
       "      <td>Fri Nov 22 22:10:28 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>22:10:28</td>\n",
       "      <td>ThatWhiteboy713</td>\n",
       "      <td>I'm sure your more of a texans hater being fro...</td>\n",
       "      <td>12212.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1197998996159115266</td>\n",
       "      <td>Fri Nov 22 22:03:13 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>22:03:13</td>\n",
       "      <td>Mbw987</td>\n",
       "      <td>Houston Texans Podcast: Week Twelve NFL Preview</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1197997776891764736</td>\n",
       "      <td>Fri Nov 22 21:58:22 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>21:58:22</td>\n",
       "      <td>schnellerdamon</td>\n",
       "      <td>Imagine Texans really believing their second r...</td>\n",
       "      <td>3945.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1197996820862922753</td>\n",
       "      <td>Fri Nov 22 21:54:34 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>21:54:34</td>\n",
       "      <td>a1cell4u</td>\n",
       "      <td>Colts' control of division goes south with los...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1197993773457977345</td>\n",
       "      <td>Fri Nov 22 21:42:27 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>21:42:27</td>\n",
       "      <td>djxbazztv</td>\n",
       "      <td>Houston Texansâ€™ DeAndre Hopkins celebrates wit...</td>\n",
       "      <td>349.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1197993765081960449</td>\n",
       "      <td>Fri Nov 22 21:42:25 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>21:42:25</td>\n",
       "      <td>lovable_daniels</td>\n",
       "      <td>Houston Texansâ€™ DeAndre Hopkins celebrates wit...</td>\n",
       "      <td>706.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1197993147667767296</td>\n",
       "      <td>Fri Nov 22 21:39:58 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>21:39:58</td>\n",
       "      <td>FPC_Bills</td>\n",
       "      <td>Per the Bills hosted OT Seantrel Henderson who...</td>\n",
       "      <td>215.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1197993130127175682</td>\n",
       "      <td>Fri Nov 22 21:39:54 +0000 2019</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>21:39:54</td>\n",
       "      <td>aaron_offline</td>\n",
       "      <td>After feeding my family In-N-Out tonight. hous...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1198351595840389121</td>\n",
       "      <td>Sat Nov 23 21:24:19 +0000 2019</td>\n",
       "      <td>2019-11-23</td>\n",
       "      <td>21:24:19</td>\n",
       "      <td>TexansPR</td>\n",
       "      <td>The Texans have signed free agent DE Joel Heat...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1200504705283084288</td>\n",
       "      <td>Fri Nov 29 20:00:00 +0000 2019</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>Patriots</td>\n",
       "      <td>\"Itâ€™s an excellent football team and thatâ€™s wh...</td>\n",
       "      <td>14693.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1200503267178024960</td>\n",
       "      <td>Fri Nov 29 19:54:17 +0000 2019</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>19:54:17</td>\n",
       "      <td>plummer4hou</td>\n",
       "      <td>Iâ€™ve spent years working in the Houston commun...</td>\n",
       "      <td>775.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                      created_at        date      time  \\\n",
       "1   1198011151688372224  Fri Nov 22 22:51:31 +0000 2019  2019-11-22  22:51:31   \n",
       "2   1198009485375225858  Fri Nov 22 22:44:53 +0000 2019  2019-11-22  22:44:53   \n",
       "3   1198008143642365952  Fri Nov 22 22:39:34 +0000 2019  2019-11-22  22:39:34   \n",
       "4   1198008131822981120  Fri Nov 22 22:39:31 +0000 2019  2019-11-22  22:39:31   \n",
       "5   1198006766241505280  Fri Nov 22 22:34:05 +0000 2019  2019-11-22  22:34:05   \n",
       "6   1198005780819169281  Fri Nov 22 22:30:10 +0000 2019  2019-11-22  22:30:10   \n",
       "7   1198003339352530945  Fri Nov 22 22:20:28 +0000 2019  2019-11-22  22:20:28   \n",
       "8   1198001802584764421  Fri Nov 22 22:14:22 +0000 2019  2019-11-22  22:14:22   \n",
       "9   1198000912985407488  Fri Nov 22 22:10:50 +0000 2019  2019-11-22  22:10:50   \n",
       "10  1198000822698889217  Fri Nov 22 22:10:28 +0000 2019  2019-11-22  22:10:28   \n",
       "11  1197998996159115266  Fri Nov 22 22:03:13 +0000 2019  2019-11-22  22:03:13   \n",
       "12  1197997776891764736  Fri Nov 22 21:58:22 +0000 2019  2019-11-22  21:58:22   \n",
       "13  1197996820862922753  Fri Nov 22 21:54:34 +0000 2019  2019-11-22  21:54:34   \n",
       "14  1197993773457977345  Fri Nov 22 21:42:27 +0000 2019  2019-11-22  21:42:27   \n",
       "15  1197993765081960449  Fri Nov 22 21:42:25 +0000 2019  2019-11-22  21:42:25   \n",
       "16  1197993147667767296  Fri Nov 22 21:39:58 +0000 2019  2019-11-22  21:39:58   \n",
       "17  1197993130127175682  Fri Nov 22 21:39:54 +0000 2019  2019-11-22  21:39:54   \n",
       "0   1198351595840389121  Sat Nov 23 21:24:19 +0000 2019  2019-11-23  21:24:19   \n",
       "19  1200504705283084288  Fri Nov 29 20:00:00 +0000 2019  2019-11-29  20:00:00   \n",
       "20  1200503267178024960  Fri Nov 29 19:54:17 +0000 2019  2019-11-29  19:54:17   \n",
       "\n",
       "               user                                               text  \\\n",
       "1      AWalkerColts  Jonathan Williamsâ€™ 13-yard touchdown run in th...   \n",
       "2           waemory  Texans are like Sam Houston, not bought for we...   \n",
       "3     Felonies4Less  Do you need to speak with Houston Texas Crimin...   \n",
       "4          Colts_TT  Colts lose to Texans: The good, the bad and th...   \n",
       "5       TexansStuff     NFL Houston Texans Stance Socks Size L - New -   \n",
       "6        OTHeroics1  Houston Texans Take Control of the AFC South w...   \n",
       "7      avpnews_live  Houston Texansâ€™ DeAndre Hopkins celebrates wit...   \n",
       "8   ChronicleTexans  New Texans from Houston Chronicle â€” McClain: T...   \n",
       "9         Texans_TT  3 players the Houston Texans can sign after Dy...   \n",
       "10  ThatWhiteboy713  I'm sure your more of a texans hater being fro...   \n",
       "11           Mbw987    Houston Texans Podcast: Week Twelve NFL Preview   \n",
       "12   schnellerdamon  Imagine Texans really believing their second r...   \n",
       "13         a1cell4u  Colts' control of division goes south with los...   \n",
       "14        djxbazztv  Houston Texansâ€™ DeAndre Hopkins celebrates wit...   \n",
       "15  lovable_daniels  Houston Texansâ€™ DeAndre Hopkins celebrates wit...   \n",
       "16        FPC_Bills  Per the Bills hosted OT Seantrel Henderson who...   \n",
       "17    aaron_offline  After feeding my family In-N-Out tonight. hous...   \n",
       "0          TexansPR  The Texans have signed free agent DE Joel Heat...   \n",
       "19         Patriots  \"Itâ€™s an excellent football team and thatâ€™s wh...   \n",
       "20      plummer4hou  Iâ€™ve spent years working in the Houston commun...   \n",
       "\n",
       "    favorite_count  year month day_of_month day_of_week  \n",
       "1           9155.0  2019    11           22           4  \n",
       "2            925.0  2019    11           22           4  \n",
       "3           8227.0  2019    11           22           4  \n",
       "4              0.0  2019    11           22           4  \n",
       "5              6.0  2019    11           22           4  \n",
       "6          10702.0  2019    11           22           4  \n",
       "7              1.0  2019    11           22           4  \n",
       "8              1.0  2019    11           22           4  \n",
       "9            945.0  2019    11           22           4  \n",
       "10         12212.0  2019    11           22           4  \n",
       "11          1014.0  2019    11           22           4  \n",
       "12          3945.0  2019    11           22           4  \n",
       "13             6.0  2019    11           22           4  \n",
       "14           349.0  2019    11           22           4  \n",
       "15           706.0  2019    11           22           4  \n",
       "16           215.0  2019    11           22           4  \n",
       "17            37.0  2019    11           22           4  \n",
       "0             63.0  2019    11           23           5  \n",
       "19         14693.0  2019    11           29           4  \n",
       "20           775.0  2019    11           29           4  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_search_df = search_range_results_df.sort_values(by=['month','day_of_month','day_of_week'], ascending=True)\n",
    "sorted_search_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "search_range_results_df shape: (29, 11)\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'search_range_results_df shape: {search_range_results_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x-rate-limit-remaining: [157]\n",
      "home_timeline: []\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'x-rate-limit-remaining: [{py_tweets.get_lastfunction_header(\"x-rate-limit-remaining\")}]')\n",
    "logger.info(f'home_timeline: {py_tweets.get_home_timeline()}')          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Full DataFrame of search results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = f'{dataDir}/{nfl_type}/{search_on}/v{search_iteration}'\n",
    "search_range_results_df.to_csv(f'{outputPath}/search_result_tweet_text_data.csv', index=False)\n",
    "search_tweets_text_meta_df.to_csv(f'{outputPath}/search_result_tweet_text_meta.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
