{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "from tweepy import OAuthHandler, Stream, StreamListener\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "from datetime import date\n",
    "from datetime import time\n",
    "from datetime import datetime\n",
    "\n",
    "# custome util package\n",
    "import rtimbroo_utils as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toggle for working with colab\n",
    "isColab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global properties\n",
    "notebook_file_name = 'stream_mine_tweets_nfl_team'\n",
    "report_file_name = 'stream_mine_tweets_nfl_team'\n",
    "app_name = 'stream_mine_tweets_nfl_team'\n",
    "log_level = 10 # 10-DEBUG, 20-INFO, 30-WARNING, 40-ERROR, 50-CRITICAL\n",
    "\n",
    "# setup working directory structure\n",
    "# set global properties\n",
    "if not isColab:\n",
    "    dataDir = './data'\n",
    "    outputDir = './output'\n",
    "    configDir = './config'\n",
    "    logOutDir = './logs'\n",
    "    imageDir = './images'\n",
    "    modelDir = './models'\n",
    "    corpusDir = './corpus'\n",
    "else:\n",
    "    # working within colab\n",
    "    dataDir = f'{base_dir}data'\n",
    "    outputDir = f'{base_dir}output'\n",
    "    configDir = f'{base_dir}config'\n",
    "    logOutDir = f'{base_dir}logs'\n",
    "    imageDir = f'{base_dir}images'\n",
    "    modelDir = f'{base_dir}models'\n",
    "    corpusDir = f'{base_dir}corpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base output directories if they don't exist\n",
    "if not os.path.exists(outputDir): os.mkdir(outputDir)\n",
    "if not os.path.exists(logOutDir): os.mkdir(logOutDir)\n",
    "if not os.path.exists(imageDir): os.mkdir(imageDir)\n",
    "if not os.path.exists(modelDir): os.mkdir(modelDir)\n",
    "if not os.path.exists(corpusDir): os.mkdir(corpusDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-11-28']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get current date\n",
    "now = datetime.utcnow().isoformat()\n",
    "collection_date = re.findall('^[0-9]{4}-[0-9]{2}-[0-9]{2}',now)\n",
    "collection_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a logger for troubleshooting / data exploration\n",
    "logger = rt.getFileLogger(logOutDir+'/',app_name+'_'+collection_date[0],level=log_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load twitter credentials\n",
    "with open(f'{configDir}/twitter_credentials.json', 'r') as f:\n",
    "    tw_cred = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set what to search on\n",
    "nfl_type = 'team'\n",
    "search_on = 'houston_texans'\n",
    "max_tweets=1000\n",
    "stream_filter_track='houston texans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StdOutListener(StreamListener):\n",
    "    \"\"\" A listener handles tweets that are received from the stream.\n",
    "    \"\"\"\n",
    "    max_tweets = 0\n",
    "    tweet_count = 0\n",
    "    tweet_filename = ''\n",
    "    raw_filename = ''\n",
    "    logger = None\n",
    "    \n",
    "    def __init__(self,logger,max_tweets,tweet_filename,raw_filename):\n",
    "        self.logger = logger\n",
    "        self.max_tweets = max_tweets\n",
    "        self.tweet_filename = tweet_filename\n",
    "        self.raw_filename = raw_filename\n",
    "        \n",
    "    #def on_status(self,status):\n",
    "       # print(f'on_status: Tweet Count: {self.tweet_count}')\n",
    "        \n",
    "    def on_data(self, data):\n",
    "        self.tweet_count+=1\n",
    "        logger.info(f'on_data: Tweet Count: {self.tweet_count}')\n",
    "        logger.debug(f'tweet data dump:\\n {data}')\n",
    "        \n",
    "        try:\n",
    "        # write the tweet text to file\n",
    "            with io.open(f'{self.tweet_filename}','a',encoding='utf8') as f:\n",
    "                logger.debug(f'Opened File {self.tweet_filename} for appending')\n",
    "                with io.open(f'{self.raw_filename}','a',encoding='utf8') as r:\n",
    "                    logger.debug(f'Opened File {self.raw_filename} for appending')\n",
    "                    \n",
    "                    # load tweet data as json\n",
    "                    logger.debug(f'Loading Tweet Data as json')\n",
    "                    raw_tweet=json.loads(data)\n",
    "                    \n",
    "                    # get tweet text\n",
    "                    tweet_text=raw_tweet['text']\n",
    "                    logger.debug(f'Tweet Text:\\n{tweet_text}\\n')\n",
    "                    logger.info(f'Writing Tweet Text to file...')\n",
    "                    f.write('\\n')\n",
    "                    f.write(tweet_text)\n",
    "                    \n",
    "                    logger.debug(f'Dump Raw Tweet Text as json:\\n{json.dumps(raw_tweet, sort_keys=True, indent=4)}')\n",
    "                    logger.info(f'Dumping Raw Tweet to file...')\n",
    "                    r.write('\\n')\n",
    "                    json.dump(raw_tweet,r)\n",
    "        \n",
    "        except BaseException as be:\n",
    "            logger.warning(f'**WARNING** Caught Exception writting tweet to file: {be}')\n",
    "            pass\n",
    "        \n",
    "        if self.tweet_count >= self.max_tweets:\n",
    "            logger.warning(f'Max Tweets Reached: {self.max_tweets}')\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        logger.error(\"ERROR\")\n",
    "        if(status==420):\n",
    "            logger.error(f'**ERROR** Rate Limited Reached | status:{status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "**ERROR** Rate Limited Reached | status:420\n",
      "ERROR\n",
      "**ERROR** Rate Limited Reached | status:420\n"
     ]
    }
   ],
   "source": [
    "# create directory path for corpus storage\n",
    "corpusPath = f'{corpusDir}/{nfl_type}/{search_on}/{collection_date}'\n",
    "if not os.path.exists(corpusPath): os.makedirs(corpusPath)\n",
    "if not os.path.exists(f'{corpusPath}/{search_on}_tweet_text.txt'): open(f'{corpusPath}/{search_on}_tweet_text.txt', 'a').close()\n",
    "if not os.path.exists(f'{corpusPath}/{search_on}_tweet_raw.txt'): open(f'{corpusPath}/{search_on}_tweet_raw.txt', 'a').close()\n",
    "\n",
    "\n",
    "tweet_filename=f'{corpusPath}/{search_on}_tweet_text.txt'\n",
    "raw_filename=f'{corpusPath}/{search_on}_tweet_raw.txt'\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "    l = StdOutListener(logger,max_tweets,tweet_filename,raw_filename)\n",
    "    auth = OAuthHandler(tw_cred['CONSUMER_KEY'], tw_cred['CONSUMER_SECRET'])\n",
    "    auth.set_access_token(tw_cred['ACCESS_TOKEN'], tw_cred['ACCESS_SECRET'])\n",
    "\n",
    "    stream = Stream(auth, l)\n",
    "    stream.filter(track=[f'{stream_filter_track}'], is_async=True)\n",
    "    \n",
    "except OSError as ose:\n",
    "    logger.error(f'**ERROR** caught exception: {ose}')\n",
    "    # try connecting again\n",
    "    l = StdOutListener(logger,max_tweets,tweet_filename,raw_filename)\n",
    "    auth = OAuthHandler(tw_cred['CONSUMER_KEY'], tw_cred['CONSUMER_SECRET'])\n",
    "    auth.set_access_token(tw_cred['ACCESS_TOKEN'], tw_cred['ACCESS_SECRET'])\n",
    "\n",
    "    stream = Stream(auth, l)\n",
    "    stream.filter(track=[f'{stream_filter_track}'], is_async=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
